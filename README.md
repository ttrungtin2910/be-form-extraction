# Form Extraction API

A FastAPI application for extracting information from forms using Google Document AI and storing results in Google Cloud Firestore.

## ğŸš€ Features


## ğŸ› ï¸ Technologies Used


## ğŸ“‹ System Requirements


## ğŸ”§ Installation

### 1. Clone repository

```bash
git clone <repository-url>
cd be-form-extraction
```

### 2. Install dependencies

```bash
conda create -n be-form-extraction python=3.12
conda activate be-form-extraction
```

```bash
pip install -r requirements.txt
```

### 3. Environment configuration

Create a `.env` file in the root directory:

```env
# OpenAI Configuration
OPENAI_KEY=your_openai_api_key
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_TEMPERATURE=0.7

# Google Cloud Configuration
PROJECT_ID=your_google_cloud_project_id
LOCATION=us
PROCESSOR_ID=your_document_ai_processor_id
PROCESSOR_VERSION_ID=your_processor_version_id
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account-key.json

# Queue / Redis
# Optional: change if not using default localhost
REDIS_URL=redis://localhost:6379/0
```

### 4. Google Cloud Setup

1. Create a service account and download JSON credentials
2. Place credentials file in `database/` or `properties/` directory
3. Configure Document AI processor
4. Create a bucket in Google Cloud Storage

## ğŸš€ Running the Application

### 0. Start Redis

```bash
docker run -d --name redis -p 6379:6379 redis:7-alpine
```

### 1. Start API (development)

```bash
uvicorn main:app --reload --port 8000
```

### 2. Start Celery worker

Python 3.13 cÃ³ thá»ƒ gáº·p lá»—i vá»›i pool máº·c Ä‘á»‹nh. DÃ¹ng script tá»± Ä‘á»™ng chá»n pool:

```bash
python scripts/run_worker.py
```

Ã‰p luÃ´n solo:
```bash
# PowerShell
$env:CELERY_FORCE_SOLO=1
python scripts/run_worker.py
```

DÃ¹ng láº¡i prefork (khuyáº¿n nghá»‹ khi á»Ÿ Python 3.12):
```bash
$env:CELERY_FORCE_SOLO=0
$env:CELERY_POOL=prefork
python scripts/run_worker.py

#### ğŸ”§ TÄƒng concurrency Ä‘á»ƒ tháº¥y nhiá»u task cháº¡y Ä‘á»“ng thá»i

Máº·c Ä‘á»‹nh Python 3.13 sáº½ bá»‹ Ã©p sang solo (1 task má»™t lÃºc). Äá»ƒ Flower hiá»ƒn thá»‹ nhiá»u task cÃ¹ng Processing:

1. (Khuyáº¿n nghá»‹) DÃ¹ng Python 3.12 vÃ  prefork:
```powershell
$env:CELERY_FORCE_SOLO=0
$env:CELERY_POOL='prefork'
$env:CELERY_CONCURRENCY=6   # sá»‘ tiáº¿n trÃ¬nh worker muá»‘n
python scripts/run_worker.py
```

2. Náº¿u váº«n á»Ÿ Python 3.13 nhÆ°ng muá»‘n thá»­ prefork (cÃ³ thá»ƒ lá»—i tÃ¹y phiÃªn báº£n Celery/billiard):
```powershell
$env:CELERY_FORCE_SOLO=0
$env:CELERY_POOL='prefork'
$env:CELERY_CONCURRENCY=4
python scripts/run_worker.py
```

3. Hoáº·c cháº¡y nhiá»u worker solo song song (má»—i terminal má»™t process):
```powershell
# Terminal 1
python scripts/run_worker.py
# Terminal 2
python scripts/run_worker.py
# ... má»—i process xá»­ lÃ½ 1 task, tá»•ng sá»‘ task cháº¡y Ä‘á»“ng thá»i = sá»‘ process
```

4. I/O-bound (gá»i API) cÃ³ thá»ƒ thá»­ eventlet/gevent (khÃ´ng báº¯t buá»™c):
```powershell
pip install eventlet
$env:CELERY_POOL='eventlet'
$env:CELERY_CONCURRENCY=50
python scripts/run_worker.py
```
LÆ°u Ã½: Kiá»ƒm soÃ¡t rate limit OpenAI / Google API, trÃ¡nh vÆ°á»£t quota.

Náº¿u tháº¥y chá»‰ 1 task Active trong Flower: kiá»ƒm tra pool (solo) hoáº·c concurrency chÆ°a Ä‘áº·t >1.
```

### 3. (Optional) Start Flower dashboard

```bash
celery -A celery_app.celery_app flower --port=5555
```

Application: `http://localhost:8000`  | Flower: `http://localhost:5555`

> Báº¡n váº«n cÃ³ thá»ƒ dÃ¹ng cÃ¡c endpoint Ä‘á»“ng bá»™ cÅ© (`/upload-image/`, `/ExtractForm`), nhÆ°ng nÃªn chuyá»ƒn sang **queue endpoints** Ä‘á»ƒ trÃ¡nh ngháº½n khi xá»­ lÃ½ nhiá»u áº£nh.

## âš™ï¸ Async Queue Endpoints

| Purpose | Sync Endpoint | Queue Endpoint | Notes |
|---------|---------------|----------------|-------|
| Upload image | `POST /upload-image/` | `POST /queue/upload-image` | Queue tráº£ vá» `task_id` |
| Extract form | `POST /ExtractForm` | `POST /queue/extract-form` | Pháº£i cÃ³ metadata áº£nh trÆ°á»›c |
| Task status  | N/A | `GET /tasks/{task_id}` | Poll tá»›i khi `state=SUCCESS` |

### Upload (Queued)
```bash
curl -X POST http://localhost:8000/queue/upload-image \
  -F "file=@sample.jpg" \
  -F "status=Uploaded" \
  -F "folderPath=2025/aug"
```
Response:
```json
{"task_id": "<uuid>", "status": "queued"}
```

### Extract (Queued)
```bash
curl -X POST http://localhost:8000/queue/extract-form \
  -H "Content-Type: application/json" \
  -d '{
    "ImageName": "20250810_101112_123456.jpg",
    "ImagePath": "https://storage.googleapis.com/display-form-extract/2025/aug/20250810_101112_123456.jpg",
    "Status": "Uploaded",
    "CreatedAt": "20250810_101112_123456",
    "FolderPath": "2025/aug",
    "Size": 1.25
  }'
```
Response:
```json
{"task_id": "<uuid>", "status": "queued"}
```

### Poll Task
```bash
curl http://localhost:8000/tasks/<uuid>
```
Possible states: `PENDING`, `STARTED`, `SUCCESS`, `FAILURE`, `RETRY`.

On success:
```json
{
  "task_id": "<uuid>",
  "state": "SUCCESS",
  "result": {"image_name": "...", "analysis_result": {"...": "..."}}
}
```

Front-end Ä‘Ã£ Ä‘Æ°á»£c cáº­p nháº­t Ä‘á»ƒ tá»± Ä‘á»™ng poll khi gá»i analyze hoáº·c bulk analyze, khÃ´ng cáº§n thay Ä‘á»•i thÃªm.

## ğŸ“š API Endpoints (Summary)

### 1. Upload Image (Sync)

**POST** `/upload-image/`

Upload form image to Google Cloud Storage and save metadata to Firestore.

```bash
curl -X POST "http://localhost:8000/upload-image/" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@form_image.jpg" \
  -F "status=pending"
```

### 2. Extract Form (Sync)

**POST** `/ExtractForm`

Extract information from form image using Google Document AI.

```bash
curl -X POST "http://localhost:8000/ExtractForm" \
  -H "Content-Type: application/json" \
  -d '{
    "title": "form_20241201_001",
    "size": "1024x768",
    "image": "https://storage.googleapis.com/bucket/image.jpg",
    "status": "processing",
    "createAt": "2024-12-01T10:00:00Z"
  }'
```

### 3. Get Extraction Information

**POST** `/GetFormExtractInformation`

Retrieve extracted information from Firestore.

```bash
curl -X POST "http://localhost:8000/GetFormExtractInformation" \
  -H "Content-Type: application/x-www-form-urlencoded" \
  -d "title=form_20241201_001"
```

### 4. Image Management

### 5. Queue Variants (Async)
See "Async Queue Endpoints" section above.


## ğŸ“ Project Structure

```
be-form-extraction/
â”œâ”€â”€ chain/                    # AI processing logic
â”‚   â”œâ”€â”€ completions.py       # OpenAI integration
â”‚   â””â”€â”€ doc_ai.py           # Google Document AI client
â”œâ”€â”€ database/                # Database operations
â”‚   â”œâ”€â”€ firestore.py        # Firestore operations
â”‚   â””â”€â”€ ggc_storage.py      # Google Cloud Storage operations
â”œâ”€â”€ properties/              # Configuration
â”‚   â”œâ”€â”€ config.py           # Environment configuration
â”‚   â””â”€â”€ prompts.py          # AI prompts
â”œâ”€â”€ utils/                   # Utility functions
â”‚   â”œâ”€â”€ common.py           # Common utilities
â”‚   â”œâ”€â”€ constant.py         # Constants
â”‚   â”œâ”€â”€ document_ai_helpers.py  # Document AI helpers
â”‚   â””â”€â”€ file_processing.py  # File processing utilities
â”œâ”€â”€ temp_uploads/           # Temporary file storage
â”œâ”€â”€ main.py                 # FastAPI application & queue endpoints
â”œâ”€â”€ celery_app.py           # Celery factory (Redis broker/backend)
â”œâ”€â”€ tasks.py                # Celery tasks (upload + extract)
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md              # This file
```

## ğŸ”’ Security


## ğŸ§ª Testing

### Test API endpoints

```bash
# Test health check
curl http://localhost:8000/

# Test upload endpoint
curl -X POST "http://localhost:8000/upload-image/" \
  -F "file=@test_image.jpg" \
  -F "status=test"
```

## ğŸ“ Logs

The application uses Python logging with INFO level. Logs are written to console and can be configured to write to files.

## ğŸš€ Deployment

### Google Cloud Run

```bash
# Build Docker image
docker build -t form-extraction-api .

# Deploy to Cloud Run
gcloud run deploy form-extraction-api \
  --image gcr.io/PROJECT_ID/form-extraction-api \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

### Docker

```bash
# Build image
docker build -t form-extraction-api .

# Run container
docker run -p 8000:8000 form-extraction-api
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“„ License

This project is distributed under the MIT License. See the `LICENSE` file for more details.

## ğŸ“ Support

If you encounter any issues or have questions, please create an issue in the repository or contact the development team.

## ï¿½ Redis Monitoring (RedisInsight)

Báº¡n cÃ³ thá»ƒ dÃ¹ng RedisInsight Ä‘á»ƒ quan sÃ¡t queue Celery (keys, performance) song song vá»›i Flower.

### CÃ¡ch 1: Docker nhanh (khuyáº¿n nghá»‹)

```powershell
docker run -d --name redisinsight -p 5540:5540 redis/redisinsight:latest
```

Má»Ÿ: http://localhost:5540

Add database:
```
Host: host.docker.internal   (hoáº·c 127.0.0.1 náº¿u Docker Desktop cho phÃ©p)
Port: 6379
Password: (Ä‘á»ƒ trá»‘ng náº¿u Redis chÆ°a Ä‘áº·t máº­t kháº©u)
```

Persist dá»¯ liá»‡u (giá»¯ cáº¥u hÃ¬nh sau khi xoÃ¡ container):
```powershell
docker run -d --name redisinsight -p 5540:5540 -v redisinsight-data:/data redis/redisinsight:latest
```

### CÃ¡ch 2: Docker Compose (Redis + RedisInsight)

Táº¡o `docker-compose.yml` (náº¿u chÆ°a cÃ³):
```yaml
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
  redisinsight:
    image: redis/redisinsight:latest
    ports:
      - "5540:5540"
    depends_on:
      - redis
    volumes:
      - redisinsight-data:/data
volumes:
  redisinsight-data:
```

Cháº¡y:
```powershell
docker compose up -d
```

### CÃ¡ch 3: CÃ i native app
Táº£i báº£n Windows tá»«: https://redis.io/insight/ â†’ Install â†’ Add database nhÆ° trÃªn.

### Xem dá»¯ liá»‡u Celery
  - `celery-task-meta-<task_id>`: tráº¡ng thÃ¡i & káº¿t quáº£ task
  - `unacked`, `celery`, v.v. (tÃ¹y broker config)

### So sÃ¡nh nhanh
| Tool | Má»¥c Ä‘Ã­ch chÃ­nh | Æ¯u Ä‘iá»ƒm | NhÆ°á»£c |
|------|----------------|---------|-------|
| Flower | GiÃ¡m sÃ¡t task (state, runtime) | UI chuyÃªn cho Celery | KhÃ´ng xem raw key | 
| RedisInsight | Quan sÃ¡t Redis cáº¥p tháº¥p | Xem key, TTL, perf, search | KhÃ´ng chuyÃªn biá»‡t Celery |

Káº¿t há»£p cáº£ hai giÃºp vá»«a tháº¥y tiáº¿n trÃ¬nh task (Flower) vá»«a xem ná»™i dung lÆ°u trong Redis (RedisInsight).

### Dá»n dáº¹p
```powershell
docker rm -f redisinsight
docker volume rm redisinsight-data   # náº¿u muá»‘n xoÃ¡ luÃ´n dá»¯ liá»‡u
```

### Troubleshooting
| Váº¥n Ä‘á» | CÃ¡ch xá»­ lÃ½ |
|--------|------------|
| KhÃ´ng connect Ä‘Æ°á»£c báº±ng 127.0.0.1 | DÃ¹ng `host.docker.internal` |
| KhÃ´ng tháº¥y key celery-task-meta-* | Task chÆ°a cháº¡y xong hoáº·c dÃ¹ng DB index khÃ¡c |
| Chá»‰ 1 task cháº¡y má»™t lÃºc | Kiá»ƒm tra pool (solo) & biáº¿n `CELERY_CONCURRENCY` |
| Timeout khi connect | Äáº£m báº£o container Redis Ä‘ang cháº¡y (docker ps) |

Muá»‘n báº£o máº­t production: báº­t password trong Redis (requirepass) rá»“i cáº¥u hÃ¬nh trong REDIS_URL (`redis://:password@host:6379/0`).

## ï¿½ğŸ”„ Changelog

### Version 1.0.0
